{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa \n",
    "import librosa.display\n",
    "import pylab\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential,Model\n",
    "from tensorflow.keras.layers import concatenate,Activation, Dense, Dropout, Conv2D, Flatten, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling1D, AveragePooling2D, Input, Add, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from sklearn.metrics import roc_curve\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../project/data/Raw_20k/'\n",
    "file_names = os.listdir('{}'.format(data_dir))\n",
    "df_list = []\n",
    "\n",
    "for file_name in file_names:\n",
    "    with open(data_dir+file_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    df_list.append(data)\n",
    "data = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_data =data.sort_values(by=['ProductCount'], axis=0)\n",
    "sort_data.reset_index(drop=True)\n",
    "\n",
    "toolcount_list = sort_data['ToolCount'].to_list()\n",
    "bites = []\n",
    "\n",
    "bite_number = 1\n",
    "current_tc = 0\n",
    "previous_tc = -1\n",
    "\n",
    "for tc in toolcount_list:\n",
    "    current_tc = tc\n",
    "\n",
    "    if current_tc >= previous_tc:\n",
    "        bites.append(bite_number)\n",
    "\n",
    "    else:\n",
    "        bite_number += 1\n",
    "        bites.append(bite_number)\n",
    "\n",
    "    previous_tc = current_tc\n",
    "\n",
    "sort_data['biteCount'] = bites\n",
    "tmpData = sort_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductCount</th>\n",
       "      <th>Current1</th>\n",
       "      <th>Current2</th>\n",
       "      <th>Current3</th>\n",
       "      <th>Vibration1</th>\n",
       "      <th>ToolCount</th>\n",
       "      <th>CurrentTool</th>\n",
       "      <th>Label</th>\n",
       "      <th>biteCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92209</td>\n",
       "      <td>[0.004208088, 0.004299879, 0.0042128563, 0.004...</td>\n",
       "      <td>[0.0011408329, 0.0011813641, 0.0011920929, 0.0...</td>\n",
       "      <td>[0.0017333031, 0.0018000603, 0.0017404556, 0.0...</td>\n",
       "      <td>[-0.0026130676, -0.0021517277, -0.0015330315, ...</td>\n",
       "      <td>192</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>92289</td>\n",
       "      <td>[0.005606413, 0.0056409836, 0.0057160854, 0.00...</td>\n",
       "      <td>[0.0011003017, 0.001064539, 0.0010597706, 0.00...</td>\n",
       "      <td>[0.0017845631, 0.0018286705, 0.0017511845, 0.0...</td>\n",
       "      <td>[-0.0027561188, -0.0033974648, -0.0038158894, ...</td>\n",
       "      <td>271</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>92288</td>\n",
       "      <td>[0.0031113625, 0.0030994415, 0.0029873848, 0.0...</td>\n",
       "      <td>[0.0010538101, 0.0010931492, 0.0012099743, 0.0...</td>\n",
       "      <td>[0.0017940998, 0.00172019, 0.0016880035, 0.001...</td>\n",
       "      <td>[-0.0034987926, -0.0028014183, -0.0023078918, ...</td>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>92287</td>\n",
       "      <td>[0.003170967, 0.0031423569, 0.0032436848, 0.00...</td>\n",
       "      <td>[0.0011491776, 0.0011754036, 0.0011098385, 0.0...</td>\n",
       "      <td>[0.0022625923, 0.0022637844, 0.002336502, 0.00...</td>\n",
       "      <td>[0.0030696392, 0.004620552, 0.0058448315, 0.00...</td>\n",
       "      <td>269</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>92286</td>\n",
       "      <td>[0.0035309792, 0.0034761429, 0.0033855438, 0.0...</td>\n",
       "      <td>[0.001270771, 0.0011539459, 0.0011944771, 0.00...</td>\n",
       "      <td>[0.0018954277, 0.0018036366, 0.0017559528, 0.0...</td>\n",
       "      <td>[-0.004144907, -0.0038564205, -0.004440546, -0...</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>94108</td>\n",
       "      <td>[0.0032019615, 0.0030839443, 0.0031507015, 0.0...</td>\n",
       "      <td>[0.0012469292, 0.0011944771, 0.0011610985, 0.0...</td>\n",
       "      <td>[0.0027775764, 0.0028669834, 0.0029051304, 0.0...</td>\n",
       "      <td>[0.001591444, 0.0017738342, 0.0017380714, 0.00...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>94107</td>\n",
       "      <td>[0.0031852722, 0.003194809, 0.0031113625, 0.00...</td>\n",
       "      <td>[0.0011146069, 0.0011634827, 0.0012171268, 0.0...</td>\n",
       "      <td>[0.0028717518, 0.0027477741, 0.0027358532, 0.0...</td>\n",
       "      <td>[0.0053215027, 0.0059628487, 0.005978346, 0.00...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>94134</td>\n",
       "      <td>[0.0033593178, 0.0034213066, 0.0034046173, 0.0...</td>\n",
       "      <td>[0.001244545, 0.001180172, 0.0011301041, 0.001...</td>\n",
       "      <td>[0.0026202202, 0.0026917458, 0.002721548, 0.00...</td>\n",
       "      <td>[0.00039696693, 0.00081419945, 0.0014281273, 0...</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>94120</td>\n",
       "      <td>[0.0030946732, 0.0030899048, 0.0031375885, 0.0...</td>\n",
       "      <td>[0.0011467934, 0.0011372566, 0.0011229515, 0.0...</td>\n",
       "      <td>[0.0023078918, 0.002233982, 0.0021839142, 0.00...</td>\n",
       "      <td>[-0.00016331673, -0.00037431717, -0.0003361702...</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>94135</td>\n",
       "      <td>[0.025507212, 0.025418997, 0.025452375, 0.0255...</td>\n",
       "      <td>[0.001142025, 0.0011718273, 0.0012266636, 0.00...</td>\n",
       "      <td>[0.0019454956, 0.0019109249, 0.0018715858, 0.0...</td>\n",
       "      <td>[0.002219677, 0.0009441376, 0.000269413, -0.00...</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1816 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ProductCount                                           Current1  \\\n",
       "0           92209  [0.004208088, 0.004299879, 0.0042128563, 0.004...   \n",
       "80          92289  [0.005606413, 0.0056409836, 0.0057160854, 0.00...   \n",
       "79          92288  [0.0031113625, 0.0030994415, 0.0029873848, 0.0...   \n",
       "78          92287  [0.003170967, 0.0031423569, 0.0032436848, 0.00...   \n",
       "77          92286  [0.0035309792, 0.0034761429, 0.0033855438, 0.0...   \n",
       "...           ...                                                ...   \n",
       "1788        94108  [0.0032019615, 0.0030839443, 0.0031507015, 0.0...   \n",
       "1787        94107  [0.0031852722, 0.003194809, 0.0031113625, 0.00...   \n",
       "1814        94134  [0.0033593178, 0.0034213066, 0.0034046173, 0.0...   \n",
       "1800        94120  [0.0030946732, 0.0030899048, 0.0031375885, 0.0...   \n",
       "1815        94135  [0.025507212, 0.025418997, 0.025452375, 0.0255...   \n",
       "\n",
       "                                               Current2  \\\n",
       "0     [0.0011408329, 0.0011813641, 0.0011920929, 0.0...   \n",
       "80    [0.0011003017, 0.001064539, 0.0010597706, 0.00...   \n",
       "79    [0.0010538101, 0.0010931492, 0.0012099743, 0.0...   \n",
       "78    [0.0011491776, 0.0011754036, 0.0011098385, 0.0...   \n",
       "77    [0.001270771, 0.0011539459, 0.0011944771, 0.00...   \n",
       "...                                                 ...   \n",
       "1788  [0.0012469292, 0.0011944771, 0.0011610985, 0.0...   \n",
       "1787  [0.0011146069, 0.0011634827, 0.0012171268, 0.0...   \n",
       "1814  [0.001244545, 0.001180172, 0.0011301041, 0.001...   \n",
       "1800  [0.0011467934, 0.0011372566, 0.0011229515, 0.0...   \n",
       "1815  [0.001142025, 0.0011718273, 0.0012266636, 0.00...   \n",
       "\n",
       "                                               Current3  \\\n",
       "0     [0.0017333031, 0.0018000603, 0.0017404556, 0.0...   \n",
       "80    [0.0017845631, 0.0018286705, 0.0017511845, 0.0...   \n",
       "79    [0.0017940998, 0.00172019, 0.0016880035, 0.001...   \n",
       "78    [0.0022625923, 0.0022637844, 0.002336502, 0.00...   \n",
       "77    [0.0018954277, 0.0018036366, 0.0017559528, 0.0...   \n",
       "...                                                 ...   \n",
       "1788  [0.0027775764, 0.0028669834, 0.0029051304, 0.0...   \n",
       "1787  [0.0028717518, 0.0027477741, 0.0027358532, 0.0...   \n",
       "1814  [0.0026202202, 0.0026917458, 0.002721548, 0.00...   \n",
       "1800  [0.0023078918, 0.002233982, 0.0021839142, 0.00...   \n",
       "1815  [0.0019454956, 0.0019109249, 0.0018715858, 0.0...   \n",
       "\n",
       "                                             Vibration1 ToolCount CurrentTool  \\\n",
       "0     [-0.0026130676, -0.0021517277, -0.0015330315, ...       192           1   \n",
       "80    [-0.0027561188, -0.0033974648, -0.0038158894, ...       271           1   \n",
       "79    [-0.0034987926, -0.0028014183, -0.0023078918, ...       270           1   \n",
       "78    [0.0030696392, 0.004620552, 0.0058448315, 0.00...       269           1   \n",
       "77    [-0.004144907, -0.0038564205, -0.004440546, -0...       268           1   \n",
       "...                                                 ...       ...         ...   \n",
       "1788  [0.001591444, 0.0017738342, 0.0017380714, 0.00...         2           1   \n",
       "1787  [0.0053215027, 0.0059628487, 0.005978346, 0.00...         1           1   \n",
       "1814  [0.00039696693, 0.00081419945, 0.0014281273, 0...        28           1   \n",
       "1800  [-0.00016331673, -0.00037431717, -0.0003361702...        14           1   \n",
       "1815  [0.002219677, 0.0009441376, 0.000269413, -0.00...        29           1   \n",
       "\n",
       "     Label  biteCount  \n",
       "0     None          1  \n",
       "80    None          1  \n",
       "79    None          1  \n",
       "78    None          1  \n",
       "77    None          1  \n",
       "...    ...        ...  \n",
       "1788  None          8  \n",
       "1787  None          8  \n",
       "1814  None          8  \n",
       "1800  None          8  \n",
       "1815  None          8  \n",
       "\n",
       "[1816 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpData.sort_values(by=['biteCount'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-b212ac2f46a2>:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  trueData1 = trueData1.append(tmpData[tmpData[\"biteCount\"] == i+1][-30:],ignore_index = True)\n",
      "<ipython-input-14-b212ac2f46a2>:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  falseData = falseData.append(tmpData[tmpData[\"biteCount\"] == i+1][:30],ignore_index= True)\n",
      "<ipython-input-14-b212ac2f46a2>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  trueData = trueData.append(tmpData[tmpData[\"biteCount\"] == i+1][-30:],ignore_index = True)\n",
      "<ipython-input-14-b212ac2f46a2>:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  falseData1 = falseData1.append(tmpData[tmpData[\"biteCount\"] == i+1][:30],ignore_index= True)\n",
      "<ipython-input-14-b212ac2f46a2>:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  trainData =  trainData.append(trueData[trueData[\"biteCount\"] < boundary])\n",
      "<ipython-input-14-b212ac2f46a2>:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  valData =  valData.append(trueData[trueData[\"biteCount\"] >= boundary])\n",
      "<ipython-input-14-b212ac2f46a2>:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  valData =  valData.append(falseData1)\n",
      "<ipython-input-14-b212ac2f46a2>:33: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  valData =  valData.append(trueData1)\n"
     ]
    }
   ],
   "source": [
    "## true False 분리\n",
    "falseData = pd.DataFrame(columns =['ProductCount','Current1','Current2','Current3','Vibration1','ToolCount','Label'])\n",
    "trueData = pd.DataFrame(columns = ['ProductCount','Current1','Current2','Current3','Vibration1','ToolCount','Label'])\n",
    "\n",
    "falseData1 = pd.DataFrame(columns =['ProductCount','Current1','Current2','Current3','Vibration1','ToolCount','Label'])\n",
    "trueData1 = pd.DataFrame(columns = ['ProductCount','Current1','Current2','Current3','Vibration1','ToolCount','Label'])\n",
    "\n",
    "for i in range(0,max(tmpData[\"biteCount\"])):\n",
    "    \n",
    "    if i == 0 : \n",
    "        trueData1 = trueData1.append(tmpData[tmpData[\"biteCount\"] == i+1][-30:],ignore_index = True)\n",
    "    elif i == 7 :\n",
    "        falseData1 = falseData1.append(tmpData[tmpData[\"biteCount\"] == i+1][:30],ignore_index= True)\n",
    "    else :\n",
    "        falseData = falseData.append(tmpData[tmpData[\"biteCount\"] == i+1][:30],ignore_index= True)\n",
    "        trueData = trueData.append(tmpData[tmpData[\"biteCount\"] == i+1][-30:],ignore_index = True)\n",
    "        \n",
    "\n",
    "falseData['Label'] = False\n",
    "trueData['Label']=True\n",
    "\n",
    "falseData1['Label'] = False\n",
    "trueData1['Label']=True\n",
    "\n",
    "boundary = round(max(tmpData[\"biteCount\"]) * 0.9)\n",
    "\n",
    "trainData = (falseData[falseData[\"biteCount\"] < boundary])\n",
    "trainData =  trainData.append(trueData[trueData[\"biteCount\"] < boundary])\n",
    "\n",
    "valData = (falseData[falseData[\"biteCount\"] >= boundary])\n",
    "valData =  valData.append(trueData[trueData[\"biteCount\"] >= boundary])\n",
    "valData =  valData.append(falseData1)\n",
    "valData =  valData.append(trueData1)\n",
    "\n",
    "pickle.dump(trainData, open( \"../project/data/experiment/V2/TrainData_XYZC_30.pickle\", \"wb\"))\n",
    "pickle.dump(valData, open( \"../project/data/experiment/V2/ValData_XYZC_30.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for CNN data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../project/data/experiment/V2/TrainData_XYZC_20.pickle\", 'rb') as f:\n",
    "    trainData = pickle.load(f)\n",
    "with open(\"../project/data/experiment/V2/ValData_XYZC_20.pickle\", 'rb') as f:\n",
    "    valData = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(row):\n",
    "    name     = str(row[0])\n",
    "    try:  \n",
    "        audio1 = np.array(row[1])\n",
    "        audio2 = np.array(row[2])\n",
    "        audio3 = np.array(row[3])\n",
    "        audio4 = np.array(row[4])\n",
    "        \n",
    "        # X\n",
    "        melX = librosa.feature.melspectrogram(y=audio1, sr=20000)\n",
    "        s_db_X     = librosa.power_to_db(melX, ref=np.max)\n",
    "        \n",
    "        pylab.axis('off') # no axis\n",
    "        pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[])\n",
    "        librosa.display.specshow(s_db_X, sr = 20000, hop_length=64)\n",
    "        x_path = os.path.join(x_figpath,name+'.png')\n",
    "        pylab.savefig(x_path, bbox_inches=None, pad_inches=0)\n",
    "        pylab.close()   \n",
    "        \n",
    "        # Y\n",
    "        melY = librosa.feature.melspectrogram(y=audio2, sr=20000)\n",
    "        s_db_Y     = librosa.power_to_db(melY, ref=np.max)\n",
    "        pylab.axis('off') # no axis\n",
    "        pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[])\n",
    "        librosa.display.specshow(s_db_Y, sr = 16000, hop_length=64)\n",
    "        y_path = os.path.join(y_figpath,name+'.png')\n",
    "        pylab.savefig(y_path, bbox_inches=None, pad_inches=0)\n",
    "        pylab.close()   \n",
    "        \n",
    "        # Z\n",
    "        melZ = librosa.feature.melspectrogram(y=audio3, sr=20000)\n",
    "        s_db_Z     = librosa.power_to_db(melZ, ref=np.max)\n",
    "        pylab.axis('off') # no axis\n",
    "        pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[])\n",
    "        librosa.display.specshow(s_db_Z, sr = 20000, hop_length=64)\n",
    "        z_path = os.path.join(z_figpath,name+'.png')\n",
    "        pylab.savefig(z_path, bbox_inches=None, pad_inches=0)\n",
    "        pylab.close()   \n",
    "        \n",
    "        # C\n",
    "        melC = librosa.feature.melspectrogram(y=audio4, sr=20000)\n",
    "        s_db_C     = librosa.power_to_db(melC, ref=np.max)\n",
    "        pylab.axis('off') # no axis\n",
    "        pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[])\n",
    "        librosa.display.specshow(s_db_C, sr = 20000, hop_length=64)\n",
    "        c_path = os.path.join(c_figpath,name+'.png')\n",
    "        pylab.savefig(c_path, bbox_inches=None, pad_inches=0)\n",
    "        pylab.close()  \n",
    "        \n",
    "    except:\n",
    "        print('file cannot open')\n",
    "        return None, None, None, None\n",
    "    return x_path, y_path, z_path, c_path\n",
    "\n",
    "\n",
    "\n",
    "def feature_extractor_mfcc(row):\n",
    "    name     = str(row[0])\n",
    "    try:  \n",
    "        audio1 = np.array(row[1])\n",
    "        audio2 = np.array(row[2])\n",
    "        audio3 = np.array(row[3])\n",
    "        audio4 = np.array(row[4])\n",
    "        \n",
    "        # X\n",
    "        mfccX = librosa.feature.mfcc(y=audio1, sr=20000, n_mfcc=40)\n",
    "        pylab.axis('off') # no axis\n",
    "        pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[])\n",
    "        librosa.display.specshow(mfccX, sr = 20000, hop_length=64)\n",
    "        x_path = os.path.join(x_figpath,name+'.png')\n",
    "        pylab.savefig(x_path, bbox_inches=None, pad_inches=0)\n",
    "        pylab.close()     \n",
    "        \n",
    "        # Y\n",
    "        mfccY = librosa.feature.mfcc(y=audio2, sr=20000, n_mfcc=40)\n",
    "        pylab.axis('off') # no axis\n",
    "        pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[])\n",
    "        librosa.display.specshow(mfccY, sr = 20000, hop_length=64)\n",
    "        y_path = os.path.join(y_figpath,name+'.png')\n",
    "        pylab.savefig(y_path, bbox_inches=None, pad_inches=0)\n",
    "        pylab.close()    \n",
    "        \n",
    "        # Z\n",
    "        mfccZ = librosa.feature.mfcc(y=audio3, sr=20000, n_mfcc=40)\n",
    "        pylab.axis('off') # no axis\n",
    "        pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[])\n",
    "        librosa.display.specshow(mfccZ, sr = 20000, hop_length=64)\n",
    "        z_path = os.path.join(z_figpath,name+'.png')\n",
    "        pylab.savefig(z_path, bbox_inches=None, pad_inches=0)\n",
    "        pylab.close()   \n",
    "        \n",
    "        # C\n",
    "        mfccC = librosa.feature.mfcc(y=audio4, sr=20000, n_mfcc=40)\n",
    "        pylab.axis('off') # no axis\n",
    "        pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[])\n",
    "        librosa.display.specshow(mfccC, sr = 20000, hop_length=64)\n",
    "        c_path = os.path.join(c_figpath,name+'.png')\n",
    "        pylab.savefig(c_path, bbox_inches=None, pad_inches=0)\n",
    "        pylab.close()   \n",
    "        \n",
    "    except:\n",
    "        print('file cannot open')\n",
    "        return None, None, None, None\n",
    "    return x_path, y_path, z_path, c_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:39<00:00,  1.88it/s]\n",
      "100%|██████████| 119/119 [00:59<00:00,  1.99it/s]\n"
     ]
    }
   ],
   "source": [
    "#train_mfcc\n",
    "x_figpath = '../project/data/mel_data_20k/Train_X_mfcc'\n",
    "y_figpath = '../project/data/mel_data_20k/Train_Y_mfcc'\n",
    "z_figpath = '../project/data/mel_data_20k/Train_Z_mfcc'\n",
    "c_figpath = '../project/data/mel_data_20k/Train_C_mfcc'\n",
    "\n",
    "x_mfcc =[]\n",
    "y_mfcc =[]\n",
    "z_mfcc =[]\n",
    "c_mfcc =[]\n",
    "\n",
    "for row in tqdm(trainData.values):\n",
    "    x_path, y_path, z_path, c_path = feature_extractor_mfcc(row)\n",
    "    x_mfcc.append(x_path)\n",
    "    y_mfcc.append(y_path)\n",
    "    z_mfcc.append(z_path)\n",
    "    c_mfcc.append(c_path)\n",
    "\n",
    "isnone = lambda x: x != None\n",
    "label  = lambda xx: 1 if xx == True else 0\n",
    "cast_x = list(map(isnone,x_mfcc)) # check missing parts \n",
    "data_y = list(map(label,trainData['Label'])) # label: Boolean -> binary\n",
    "data_x1 = [x_mfcc[i] for i in range(len(x_mfcc)) if cast_x[i] == True] # mel-sp = x\n",
    "data_x2 = [y_mfcc[i] for i in range(len(y_mfcc)) if cast_x[i] == True] # mel-sp = y\n",
    "data_x3 = [z_mfcc[i] for i in range(len(z_mfcc)) if cast_x[i] == True] # mel-sp = z\n",
    "data_x4 = [c_mfcc[i] for i in range(len(c_mfcc)) if cast_x[i] == True] # mel-sp = c\n",
    "data_y = [data_y[i] for i in range(len(x_mfcc)) if cast_x[i] == True] # label = y \n",
    "\n",
    "\n",
    "indices = np.arange(len(data_x1))\n",
    "train_DATA_mfcc    = {}\n",
    "np.random.shuffle(indices)\n",
    "train_DATA_mfcc['MFCC_X'] = [data_x1[i] for i in indices]\n",
    "train_DATA_mfcc['MFCC_Y'] = [data_x2[i] for i in indices]\n",
    "train_DATA_mfcc['MFCC_Z'] = [data_x3[i] for i in indices]\n",
    "train_DATA_mfcc['MFCC_C'] = [data_x4[i] for i in indices]\n",
    "train_DATA_mfcc['LABEL'] = [data_y[i] for i in indices]\n",
    "\n",
    "\n",
    "# Val mfcc 저장\n",
    "x_figpath = '../project/data/mel_data_20k/Val_X_mfcc'\n",
    "y_figpath = '../project/data/mel_data_20k/Val_Y_mfcc'\n",
    "z_figpath = '../project/data/mel_data_20k/Val_Z_mfcc'\n",
    "c_figpath = '../project/data/mel_data_20k/Val_C_mfcc'\n",
    "\n",
    "# valData_mfcc\n",
    "x_mfcc =[]\n",
    "y_mfcc =[]\n",
    "z_mfcc =[]\n",
    "c_mfcc =[]\n",
    "\n",
    "#저장후 이미지 경로 리스트에 저장\n",
    "for row in tqdm(valData.values):\n",
    "    x_path, y_path, z_path, c_path = feature_extractor_mfcc(row)\n",
    "    x_mfcc.append(x_path)\n",
    "    y_mfcc.append(y_path)\n",
    "    z_mfcc.append(z_path)\n",
    "    c_mfcc.append(c_path)\n",
    "\n",
    "#None 아닌 데이터만 추출 및 label 1,0으로 저장\n",
    "isnone = lambda x: x != None\n",
    "label  = lambda xx: 1 if xx == True else 0\n",
    "cast_x = list(map(isnone,x_mfcc)) # check missing parts \n",
    "data_y = list(map(label,valData['Label'])) # label: Boolean -> binary\n",
    "data_x1_val = [x_mfcc[i] for i in range(len(x_mfcc)) if cast_x[i] == True] # mel-sp = x\n",
    "data_x2_val = [y_mfcc[i] for i in range(len(y_mfcc)) if cast_x[i] == True] # mel-sp = y\n",
    "data_x3_val = [z_mfcc[i] for i in range(len(z_mfcc)) if cast_x[i] == True] # mel-sp = z\n",
    "data_x4_val = [c_mfcc[i] for i in range(len(c_mfcc)) if cast_x[i] == True] # mel-sp = c\n",
    "data_y_val = [data_y[i] for i in range(len(x_mfcc)) if cast_x[i] == True] # label = y \n",
    "\n",
    "indices = np.arange(len(data_x1_val))\n",
    "test_DATA_mfcc    = {}\n",
    "np.random.shuffle(indices)\n",
    "test_DATA_mfcc['MFCC_X'] = [data_x1_val[i] for i in indices]\n",
    "test_DATA_mfcc['MFCC_Y'] = [data_x2_val[i] for i in indices]\n",
    "test_DATA_mfcc['MFCC_Z'] = [data_x3_val[i] for i in indices]\n",
    "test_DATA_mfcc['MFCC_C'] = [data_x4_val[i] for i in indices]\n",
    "test_DATA_mfcc['LABEL'] = [data_y_val[i] for i in indices]\n",
    "\n",
    "pickle.dump(train_DATA_mfcc, open( \"../project/data/modeling_data/V2/TrainData_XYZC_MFCC_30.pickle\", \"wb\"))\n",
    "pickle.dump(test_DATA_mfcc, open( \"../project/data/modeling_data/V2/ValData_XYZC_MFCC_30.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:21<00:00,  1.41it/s]\n",
      "100%|██████████| 80/80 [00:59<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# # Train mel 저장\n",
    "x_figpath = '../project/data/mel_data_20k/Train_X'\n",
    "y_figpath = '../project/data/mel_data_20k/Train_Y'\n",
    "z_figpath = '../project/data/mel_data_20k/Train_Z'\n",
    "c_figpath = '../project/data/mel_data_20k/Train_C'\n",
    "\n",
    "# valData_mel\n",
    "x_mel =[]\n",
    "y_mel =[]\n",
    "z_mel =[]\n",
    "c_mel =[]\n",
    "\n",
    "#저장후 이미지 경로 리스트에 저장\n",
    "for row in tqdm(trainData.values):\n",
    "    x_path, y_path, z_path, c_path = feature_extractor(row)\n",
    "    x_mel.append(x_path)\n",
    "    y_mel.append(y_path)\n",
    "    z_mel.append(z_path)\n",
    "    c_mel.append(c_path)\n",
    "\n",
    "\n",
    "#None 아닌 데이터만 추출 및 label 1,0으로 저장\n",
    "isnone = lambda x: x != None\n",
    "label  = lambda xx: 1 if xx == True else 0\n",
    "cast_x = list(map(isnone,x_mel)) # check missing parts \n",
    "data_y = list(map(label,trainData['Label'])) # label: Boolean -> binary\n",
    "data_x1 = [x_mel[i] for i in range(len(x_mel)) if cast_x[i] == True] # mel-sp = x\n",
    "data_x2 = [y_mel[i] for i in range(len(y_mel)) if cast_x[i] == True] # mel-sp = y\n",
    "data_x3 = [z_mel[i] for i in range(len(z_mel)) if cast_x[i] == True] # mel-sp = z\n",
    "data_x4 = [c_mel[i] for i in range(len(c_mel)) if cast_x[i] == True] # mel-sp = c\n",
    "data_y = [data_y[i] for i in range(len(x_mel)) if cast_x[i] == True] # label = y \n",
    "\n",
    "indices = np.arange(len(data_x1))\n",
    "train_DATA    = {}\n",
    "np.random.shuffle(indices)\n",
    "train_DATA['MEL_X'] = [data_x1[i] for i in indices]\n",
    "train_DATA['MEL_Y'] = [data_x2[i] for i in indices]\n",
    "train_DATA['MEL_Z'] = [data_x3[i] for i in indices]\n",
    "train_DATA['MEL_C'] = [data_x4[i] for i in indices]\n",
    "train_DATA['LABEL'] = [data_y[i] for i in indices]\n",
    "\n",
    "# # Val mel 저장\n",
    "x_figpath = '../project/data/mel_data_20k/Val_X'\n",
    "y_figpath = '../project/data/mel_data_20k/Val_Y'\n",
    "z_figpath = '../project/data/mel_data_20k/Val_Z'\n",
    "c_figpath = '../project/data/mel_data_20k/Val_C'\n",
    "\n",
    "# valData_mel\n",
    "x_mel =[]\n",
    "y_mel =[]\n",
    "z_mel =[]\n",
    "c_mel =[]\n",
    "\n",
    "#저장후 이미지 경로 리스트에 저장\n",
    "for row in tqdm(valData.values):\n",
    "    x_path, y_path, z_path, c_path = feature_extractor(row)\n",
    "    x_mel.append(x_path)\n",
    "    y_mel.append(y_path)\n",
    "    z_mel.append(z_path)\n",
    "    c_mel.append(c_path)\n",
    "\n",
    "\n",
    "#None 아닌 데이터만 추출 및 label 1,0으로 저장\n",
    "isnone = lambda x: x != None\n",
    "label  = lambda xx: 1 if xx == True else 0\n",
    "cast_x = list(map(isnone,x_mel)) # check missing parts \n",
    "data_y = list(map(label,valData['Label'])) # label: Boolean -> binary\n",
    "data_x1_val = [x_mel[i] for i in range(len(x_mel)) if cast_x[i] == True] # mel-sp = x\n",
    "data_x2_val = [y_mel[i] for i in range(len(y_mel)) if cast_x[i] == True] # mel-sp = y\n",
    "data_x3_val = [z_mel[i] for i in range(len(z_mel)) if cast_x[i] == True] # mel-sp = z\n",
    "data_x4_val = [c_mel[i] for i in range(len(c_mel)) if cast_x[i] == True] # mel-sp = c\n",
    "data_y_val = [data_y[i] for i in range(len(x_mel)) if cast_x[i] == True] # label = y \n",
    "\n",
    "indices = np.arange(len(data_x1_val))\n",
    "test_DATA    = {}\n",
    "np.random.shuffle(indices)\n",
    "test_DATA['MEL_X'] = [data_x1_val[i] for i in indices]\n",
    "test_DATA['MEL_Y'] = [data_x2_val[i] for i in indices]\n",
    "test_DATA['MEL_Z'] = [data_x3_val[i] for i in indices]\n",
    "test_DATA['MEL_C'] = [data_x4_val[i] for i in indices]\n",
    "test_DATA['LABEL'] = [data_y_val[i] for i in indices]\n",
    "\n",
    "pickle.dump(train_DATA, open( \"../project/data/modeling_data/V2/TrainData_XYZC_30.pickle\", \"wb\"))\n",
    "pickle.dump(test_DATA, open( \"../project/data/modeling_data/V2/ValData_XYZC_30.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for RNN data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../project/data/experiment/V2/TrainData_XYZC_20.pickle\", 'rb') as f:\n",
    "    trainData = pickle.load(f)\n",
    "with open(\"../project/data/experiment/V2/ValData_XYZC_20.pickle\", 'rb') as f:\n",
    "    valData = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(row):      \n",
    "    # Vibration\n",
    "    audio = np.array(row[4])\n",
    "    mfccs_per_frame = 20\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=20000, n_mfcc=mfccs_per_frame)\n",
    "    return mfcc\n",
    "\n",
    "def feature_extractor_forRNN(row, pad_length):\n",
    "    name     = str(row[0])\n",
    "    try:        \n",
    "        # Vibration\n",
    "        audio = np.array(row[4])\n",
    "        mfccs_per_frame = 20\n",
    "        mfcc = librosa.feature.mfcc(y=audio, sr=20000, n_mfcc=mfccs_per_frame)\n",
    "        pad_width = pad_length - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width))).reshape((mfccs_per_frame,pad_length))\n",
    "        \n",
    "    except:\n",
    "        print('file cannot open')\n",
    "        return None\n",
    "    return name, mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "821\n"
     ]
    }
   ],
   "source": [
    "pad_length = 0\n",
    "for row in trainData.values:\n",
    "    mfcc = feature_extractor(row)\n",
    "    if pad_length < mfcc.shape[1] :\n",
    "        pad_length = mfcc.shape[1]       \n",
    "print(pad_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:06<00:00, 31.89it/s]\n",
      "100%|██████████| 80/80 [00:02<00:00, 35.03it/s]\n"
     ]
    }
   ],
   "source": [
    "#train_mfcc\n",
    "v_mfcc = []\n",
    "pname = []\n",
    "\n",
    "for row in tqdm(trainData.values):\n",
    "    name, mfcc = feature_extractor_forRNN(row, pad_length)\n",
    "    v_mfcc.append(mfcc)\n",
    "    pname.append(name)\n",
    "\n",
    "isnone = lambda x: x != None\n",
    "label  = lambda xx: 1 if xx == True else 0\n",
    "data_y = list(map(label,trainData['Label'])) # label: Boolean -> binary\n",
    "data_x = [v_mfcc[i] for i in range(len(v_mfcc))] # mel-sp = c\n",
    "data_id = [pname[i] for i in range(len(pname))] # mel-sp = c\n",
    "data_y = [data_y[i] for i in range(len(v_mfcc))] # label = y \n",
    "\n",
    "indices = np.arange(len(data_x))\n",
    "train_DATA_mfcc    = {}\n",
    "np.random.shuffle(indices)\n",
    "train_DATA_mfcc['MFCC'] = [data_x[i] for i in indices]\n",
    "train_DATA_mfcc['PNAME'] = [data_id[i] for i in indices]\n",
    "train_DATA_mfcc['LABEL'] = [data_y[i] for i in indices]\n",
    "\n",
    "# valData_mfcc\n",
    "v_mfcc = []\n",
    "pname = []\n",
    "\n",
    "#저장후 이미지 경로 리스트에 저장\n",
    "for row in tqdm(valData.values):\n",
    "    name, mfcc = feature_extractor_forRNN(row, pad_length)\n",
    "    v_mfcc.append(mfcc)\n",
    "    pname.append(name)\n",
    "    \n",
    "#None 아닌 데이터만 추출 및 label 1,0으로 저장\n",
    "isnone = lambda x: x != None\n",
    "label  = lambda xx: 1 if xx == True else 0\n",
    "data_y = list(map(label,valData['Label'])) # label: Boolean -> binary\n",
    "data_x_val = [v_mfcc[i] for i in range(len(v_mfcc))] # mel-sp = c\n",
    "data_id_val = [pname[i] for i in range(len(pname))] # mel-sp = c\n",
    "data_y_val = [data_y[i] for i in range(len(v_mfcc))] # label = y \n",
    "\n",
    "indices = np.arange(len(data_x_val))\n",
    "test_DATA_mfcc    = {}\n",
    "np.random.shuffle(indices)\n",
    "test_DATA_mfcc['MFCC'] = [data_x_val[i] for i in indices]\n",
    "test_DATA_mfcc['PNAME'] = [data_id_val[i] for i in indices]\n",
    "test_DATA_mfcc['LABEL'] = [data_y_val[i] for i in indices]\n",
    "\n",
    "pickle.dump(train_DATA_mfcc, open( \"../project/data/modeling_data/V2/TrainData_MFCC_20_20_forRNN.pickle\", \"wb\"))\n",
    "pickle.dump(test_DATA_mfcc, open( \"../project/data/modeling_data/V2/ValData_MFCC_20_20_forRNN.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for 20khz sampling rate experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../project/data/experiment/V2/TrainData_XYZC_20.pickle\", 'rb') as f:\n",
    "    trainData = pickle.load(f)\n",
    "with open(\"../project/data/experiment/V2/ValData_XYZC_20.pickle\", 'rb') as f:\n",
    "    valData = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor_SR(row):\n",
    "    name     = str(row[0])\n",
    "    try:  \n",
    "        audio = np.array(row[4])\n",
    "        \n",
    "        # 8000\n",
    "        melX = librosa.feature.melspectrogram(y=audio, sr=8000)\n",
    "        s_db_X     = librosa.power_to_db(melX, ref=np.max)\n",
    "        \n",
    "        pylab.axis('off') # no axis\n",
    "        pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[])\n",
    "        librosa.display.specshow(s_db_X, sr = 8000, hop_length=64)\n",
    "        x_path = os.path.join(x_figpath,name+'.png')\n",
    "        pylab.savefig(x_path, bbox_inches=None, pad_inches=0)\n",
    "        pylab.close()   \n",
    "        \n",
    "        # 24000\n",
    "        melY = librosa.feature.melspectrogram(y=audio, sr=24000)\n",
    "        s_db_Y     = librosa.power_to_db(melY, ref=np.max)\n",
    "        pylab.axis('off') # no axis\n",
    "        pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[])\n",
    "        librosa.display.specshow(s_db_Y, sr = 24000, hop_length=64)\n",
    "        y_path = os.path.join(y_figpath,name+'.png')\n",
    "        pylab.savefig(y_path, bbox_inches=None, pad_inches=0)\n",
    "        pylab.close()   \n",
    "        \n",
    "        # 28000\n",
    "        melZ = librosa.feature.melspectrogram(y=audio, sr=28000)\n",
    "        s_db_Z     = librosa.power_to_db(melZ, ref=np.max)\n",
    "        pylab.axis('off') # no axis\n",
    "        pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[])\n",
    "        librosa.display.specshow(s_db_Z, sr = 28000, hop_length=64)\n",
    "        z_path = os.path.join(z_figpath,name+'.png')\n",
    "        pylab.savefig(z_path, bbox_inches=None, pad_inches=0)\n",
    "        pylab.close()   \n",
    "        \n",
    "        # 32000\n",
    "        melC = librosa.feature.melspectrogram(y=audio, sr=32000)\n",
    "        s_db_C     = librosa.power_to_db(melC, ref=np.max)\n",
    "        pylab.axis('off') # no axis\n",
    "        pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[])\n",
    "        librosa.display.specshow(s_db_C, sr = 32000, hop_length=64)\n",
    "        c_path = os.path.join(c_figpath,name+'.png')\n",
    "        pylab.savefig(c_path, bbox_inches=None, pad_inches=0)\n",
    "        pylab.close()  \n",
    "        \n",
    "    except:\n",
    "        print('file cannot open')\n",
    "        return None, None, None, None\n",
    "    return x_path, y_path, z_path, c_path\n",
    "\n",
    "\n",
    "\n",
    "def feature_extractor_mfcc_SR(row):\n",
    "    name     = str(row[0])\n",
    "    try:  \n",
    "        audio = np.array(row[4]) \n",
    "        # 16000\n",
    "        mfccX = librosa.feature.mfcc(y=audio, sr=16000, n_mfcc=40)\n",
    "        pylab.axis('off') # no axis\n",
    "        pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[])\n",
    "        librosa.display.specshow(mfccX, sr = 16000, hop_length=64)\n",
    "        x_path = os.path.join(x_figpath,name+'.png')\n",
    "        pylab.savefig(x_path, bbox_inches=None, pad_inches=0)\n",
    "        pylab.close()     \n",
    "        \n",
    "        # 20000\n",
    "        mfccY = librosa.feature.mfcc(y=audio, sr=20000, n_mfcc=40)\n",
    "        pylab.axis('off') # no axis\n",
    "        pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[])\n",
    "        librosa.display.specshow(mfccY, sr = 20000, hop_length=64)\n",
    "        y_path = os.path.join(y_figpath,name+'.png')\n",
    "        pylab.savefig(y_path, bbox_inches=None, pad_inches=0)\n",
    "        pylab.close()    \n",
    "        \n",
    "        # 28000\n",
    "        mfccZ = librosa.feature.mfcc(y=audio, sr=28000, n_mfcc=40)\n",
    "        pylab.axis('off') # no axis\n",
    "        pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[])\n",
    "        librosa.display.specshow(mfccZ, sr = 28000, hop_length=64)\n",
    "        z_path = os.path.join(z_figpath,name+'.png')\n",
    "        pylab.savefig(z_path, bbox_inches=None, pad_inches=0)\n",
    "        pylab.close()   \n",
    "        \n",
    "        # 32000\n",
    "        mfccC = librosa.feature.mfcc(y=audio, sr=32000, n_mfcc=40)\n",
    "        pylab.axis('off') # no axis\n",
    "        pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[])\n",
    "        librosa.display.specshow(mfccC, sr = 32000, hop_length=64)\n",
    "        c_path = os.path.join(c_figpath,name+'.png')\n",
    "        pylab.savefig(c_path, bbox_inches=None, pad_inches=0)\n",
    "        pylab.close()   \n",
    "        \n",
    "    except:\n",
    "        print('file cannot open')\n",
    "        return None, None, None, None\n",
    "    return x_path, y_path, z_path, c_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:46<00:00,  1.87it/s]\n",
      "100%|██████████| 80/80 [00:43<00:00,  1.82it/s]\n"
     ]
    }
   ],
   "source": [
    "#train_mfcc\n",
    "x_figpath = '../project/data/mel_data_20k/20kSR/Train_mfcc40_16000'\n",
    "y_figpath = '../project/data/mel_data_20k/20kSR/Train_mfcc40_20000'\n",
    "z_figpath = '../project/data/mel_data_20k/20kSR/Train_mfcc40_28000'\n",
    "c_figpath = '../project/data/mel_data_20k/20kSR/Train_mfcc40_32000'\n",
    "\n",
    "x_mfcc =[]\n",
    "y_mfcc =[]\n",
    "z_mfcc =[]\n",
    "c_mfcc =[]\n",
    "\n",
    "for row in tqdm(trainData.values):\n",
    "    x_path, y_path, z_path, c_path = feature_extractor_mfcc_SR(row)\n",
    "    x_mfcc.append(x_path)\n",
    "    y_mfcc.append(y_path)\n",
    "    z_mfcc.append(z_path)\n",
    "    c_mfcc.append(c_path)\n",
    "\n",
    "isnone = lambda x: x != None\n",
    "label  = lambda xx: 1 if xx == True else 0\n",
    "cast_x = list(map(isnone,x_mfcc)) # check missing parts \n",
    "data_y = list(map(label,trainData['Label'])) # label: Boolean -> binary\n",
    "data_x1 = [x_mfcc[i] for i in range(len(x_mfcc)) if cast_x[i] == True] # mel-sp = x\n",
    "data_x2 = [y_mfcc[i] for i in range(len(y_mfcc)) if cast_x[i] == True] # mel-sp = y\n",
    "data_x3 = [z_mfcc[i] for i in range(len(z_mfcc)) if cast_x[i] == True] # mel-sp = z\n",
    "data_x4 = [c_mfcc[i] for i in range(len(c_mfcc)) if cast_x[i] == True] # mel-sp = c\n",
    "data_y = [data_y[i] for i in range(len(x_mfcc)) if cast_x[i] == True] # label = y \n",
    "\n",
    "\n",
    "indices = np.arange(len(data_x1))\n",
    "train_DATA_mfcc    = {}\n",
    "np.random.shuffle(indices)\n",
    "train_DATA_mfcc['MFCC_16000'] = [data_x1[i] for i in indices]\n",
    "train_DATA_mfcc['MFCC_20000'] = [data_x2[i] for i in indices]\n",
    "train_DATA_mfcc['MFCC_28000'] = [data_x3[i] for i in indices]\n",
    "train_DATA_mfcc['MFCC_32000'] = [data_x4[i] for i in indices]\n",
    "train_DATA_mfcc['LABEL'] = [data_y[i] for i in indices]\n",
    "\n",
    "\n",
    "# Val mfcc 저장\n",
    "x_figpath = '../project/data/mel_data_20k/20kSR/Val_mfcc40_16000'\n",
    "y_figpath = '../project/data/mel_data_20k/20kSR/Val_mfcc40_20000'\n",
    "z_figpath = '../project/data/mel_data_20k/20kSR/Val_mfcc40_28000'\n",
    "c_figpath = '../project/data/mel_data_20k/20kSR/Val_mfcc40_32000'\n",
    "\n",
    "# valData_mfcc\n",
    "x_mfcc =[]\n",
    "y_mfcc =[]\n",
    "z_mfcc =[]\n",
    "c_mfcc =[]\n",
    "\n",
    "#저장후 이미지 경로 리스트에 저장\n",
    "for row in tqdm(valData.values):\n",
    "    x_path, y_path, z_path, c_path = feature_extractor_mfcc_SR(row)\n",
    "    x_mfcc.append(x_path)\n",
    "    y_mfcc.append(y_path)\n",
    "    z_mfcc.append(z_path)\n",
    "    c_mfcc.append(c_path)\n",
    "\n",
    "#None 아닌 데이터만 추출 및 label 1,0으로 저장\n",
    "isnone = lambda x: x != None\n",
    "label  = lambda xx: 1 if xx == True else 0\n",
    "cast_x = list(map(isnone,x_mfcc)) # check missing parts \n",
    "data_y = list(map(label,valData['Label'])) # label: Boolean -> binary\n",
    "data_x1_val = [x_mfcc[i] for i in range(len(x_mfcc)) if cast_x[i] == True] # mel-sp = x\n",
    "data_x2_val = [y_mfcc[i] for i in range(len(y_mfcc)) if cast_x[i] == True] # mel-sp = y\n",
    "data_x3_val = [z_mfcc[i] for i in range(len(z_mfcc)) if cast_x[i] == True] # mel-sp = z\n",
    "data_x4_val = [c_mfcc[i] for i in range(len(c_mfcc)) if cast_x[i] == True] # mel-sp = c\n",
    "data_y_val = [data_y[i] for i in range(len(x_mfcc)) if cast_x[i] == True] # label = y \n",
    "\n",
    "indices = np.arange(len(data_x1_val))\n",
    "test_DATA_mfcc    = {}\n",
    "np.random.shuffle(indices)\n",
    "test_DATA_mfcc['MFCC_16000'] = [data_x1_val[i] for i in indices]\n",
    "test_DATA_mfcc['MFCC_20000'] = [data_x2_val[i] for i in indices]\n",
    "test_DATA_mfcc['MFCC_28000'] = [data_x3_val[i] for i in indices]\n",
    "test_DATA_mfcc['MFCC_32000'] = [data_x4_val[i] for i in indices]\n",
    "test_DATA_mfcc['LABEL'] = [data_y_val[i] for i in indices]\n",
    "\n",
    "pickle.dump(train_DATA_mfcc, open( \"../project/data/modeling_data/V2/TrainData_MFCC40_SR+.pickle\", \"wb\"))\n",
    "pickle.dump(test_DATA_mfcc, open( \"../project/data/modeling_data/V2/ValData_MFCC40_SR+.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [04:13<00:00,  1.27s/it]\n",
      "100%|██████████| 80/80 [01:12<00:00,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# # Train mel 저장\n",
    "x_figpath = '../project/data/mel_data_20k/20kSR/Train_8000'\n",
    "y_figpath = '../project/data/mel_data_20k/20kSR/Train_24000'\n",
    "z_figpath = '../project/data/mel_data_20k/20kSR/Train_28000'\n",
    "c_figpath = '../project/data/mel_data_20k/20kSR/Train_32000'\n",
    "\n",
    "# valData_mel\n",
    "x_mel =[]\n",
    "y_mel =[]\n",
    "z_mel =[]\n",
    "c_mel =[]\n",
    "\n",
    "#저장후 이미지 경로 리스트에 저장\n",
    "for row in tqdm(trainData.values):\n",
    "    x_path, y_path, z_path, c_path = feature_extractor_SR(row)\n",
    "    x_mel.append(x_path)\n",
    "    y_mel.append(y_path)\n",
    "    z_mel.append(z_path)\n",
    "    c_mel.append(c_path)\n",
    "\n",
    "\n",
    "#None 아닌 데이터만 추출 및 label 1,0으로 저장\n",
    "isnone = lambda x: x != None\n",
    "label  = lambda xx: 1 if xx == True else 0\n",
    "cast_x = list(map(isnone,x_mel)) # check missing parts \n",
    "data_y = list(map(label,trainData['Label'])) # label: Boolean -> binary\n",
    "data_x1 = [x_mel[i] for i in range(len(x_mel)) if cast_x[i] == True] # mel-sp = x\n",
    "data_x2 = [y_mel[i] for i in range(len(y_mel)) if cast_x[i] == True] # mel-sp = y\n",
    "data_x3 = [z_mel[i] for i in range(len(z_mel)) if cast_x[i] == True] # mel-sp = z\n",
    "data_x4 = [c_mel[i] for i in range(len(c_mel)) if cast_x[i] == True] # mel-sp = c\n",
    "data_y = [data_y[i] for i in range(len(x_mel)) if cast_x[i] == True] # label = y \n",
    "\n",
    "indices = np.arange(len(data_x1))\n",
    "train_DATA    = {}\n",
    "np.random.shuffle(indices)\n",
    "train_DATA['MEL_8000'] = [data_x1[i] for i in indices]\n",
    "train_DATA['MEL_24000'] = [data_x2[i] for i in indices]\n",
    "train_DATA['MEL_28000'] = [data_x3[i] for i in indices]\n",
    "train_DATA['MEL_32000'] = [data_x4[i] for i in indices]\n",
    "train_DATA['LABEL'] = [data_y[i] for i in indices]\n",
    "\n",
    "# # Val mel 저장\n",
    "x_figpath = '../project/data/mel_data_20k/20kSR/Val_8000'\n",
    "y_figpath = '../project/data/mel_data_20k/20kSR/Val_24000'\n",
    "z_figpath = '../project/data/mel_data_20k/20kSR/Val_28000'\n",
    "c_figpath = '../project/data/mel_data_20k/20kSR/Val_32000'\n",
    "\n",
    "# valData_mel\n",
    "x_mel =[]\n",
    "y_mel =[]\n",
    "z_mel =[]\n",
    "c_mel =[]\n",
    "\n",
    "#저장후 이미지 경로 리스트에 저장\n",
    "for row in tqdm(valData.values):\n",
    "    x_path, y_path, z_path, c_path = feature_extractor_SR(row)\n",
    "    x_mel.append(x_path)\n",
    "    y_mel.append(y_path)\n",
    "    z_mel.append(z_path)\n",
    "    c_mel.append(c_path)\n",
    "\n",
    "\n",
    "#None 아닌 데이터만 추출 및 label 1,0으로 저장\n",
    "isnone = lambda x: x != None\n",
    "label  = lambda xx: 1 if xx == True else 0\n",
    "cast_x = list(map(isnone,x_mel)) # check missing parts \n",
    "data_y = list(map(label,valData['Label'])) # label: Boolean -> binary\n",
    "data_x1_val = [x_mel[i] for i in range(len(x_mel)) if cast_x[i] == True] # mel-sp = x\n",
    "data_x2_val = [y_mel[i] for i in range(len(y_mel)) if cast_x[i] == True] # mel-sp = y\n",
    "data_x3_val = [z_mel[i] for i in range(len(z_mel)) if cast_x[i] == True] # mel-sp = z\n",
    "data_x4_val = [c_mel[i] for i in range(len(c_mel)) if cast_x[i] == True] # mel-sp = c\n",
    "data_y_val = [data_y[i] for i in range(len(x_mel)) if cast_x[i] == True] # label = y \n",
    "\n",
    "indices = np.arange(len(data_x1_val))\n",
    "test_DATA    = {}\n",
    "np.random.shuffle(indices)\n",
    "test_DATA['MEL_8000'] = [data_x1_val[i] for i in indices]\n",
    "test_DATA['MEL_24000'] = [data_x2_val[i] for i in indices]\n",
    "test_DATA['MEL_28000'] = [data_x3_val[i] for i in indices]\n",
    "test_DATA['MEL_32000'] = [data_x4_val[i] for i in indices]\n",
    "test_DATA['LABEL'] = [data_y_val[i] for i in indices]\n",
    "\n",
    "pickle.dump(train_DATA, open( \"../project/data/modeling_data/V2/TrainData_SR.pickle\", \"wb\"))\n",
    "pickle.dump(test_DATA, open( \"../project/data/modeling_data/V2/ValData_SR.pickle\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
